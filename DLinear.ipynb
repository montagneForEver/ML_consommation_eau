{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfba693",
   "metadata": {},
   "source": [
    "# DLinear\n",
    "\n",
    "Ce notebook produit un modele DLinear entrainé pour chaque série et d'évalue sa performance.\n",
    "\n",
    "Le modele est reconstruit dans pytorch 1.13 compatible avec mon GPU M640.\n",
    "\n",
    "l'objectif est :\n",
    "- tester la performance d'un modèle DLinear sur le probleme de détection des anomalies de consommation\n",
    "- s'entrainer à l'utilisation de pytorch\n",
    "- disposer d'un modèle DLinear compatible avec pytorch 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b3ce3",
   "metadata": {},
   "source": [
    "## Imports et paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45b11ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717dc265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "Quadro M620\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de0035",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'moving_avg_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m params\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoving_avg_window\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindows_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_avg_window\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'moving_avg_window'"
     ]
    }
   ],
   "source": [
    "params={\n",
    "'moving_avg_window':5,\n",
    "'windows_batch_size':20,\n",
    "'inference_windows_batch_size':10,\n",
    "\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327b832",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'moving_avg_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_avg_window\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'moving_avg_window'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6704a366",
   "metadata": {},
   "source": [
    "## Chargement et pré_traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a935e7",
   "metadata": {},
   "source": [
    "### Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e29e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Chargement des données *** \n",
      "\n",
      "Affichage des premières lignes du dataset : \n",
      "\n",
      "    valeur_active valeur_date libelle\n",
      "0           35.0  2019-01-01    ID_1\n",
      "1            0.0  2019-01-01    ID_2\n",
      "2            2.0  2019-01-01    ID_3\n",
      "3           38.0  2019-01-01    ID_4\n",
      "4           38.0  2019-01-01    ID_5 \n",
      "\n",
      "\n",
      "Dimension du dataset : (470900, 3)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/\"\n",
    "project_name_eau = \"detection_fuite.csv\"\n",
    "\n",
    "print(\"*** Chargement des données *** \\n\")\n",
    "data_eau = pd.read_csv(f\"{file_path}/{project_name_eau}\")\n",
    "print(f\"Affichage des premières lignes du dataset : \\n\\n {data_eau.head()} \\n\\n\")\n",
    "print(f\"Dimension du dataset : {data_eau.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eab7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion date et tri\n",
    "data_eau[\"date\"] = pd.to_datetime(data_eau[\"valeur_date\"])\n",
    "data_eau=data_eau.sort_values(['libelle','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf94044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sélection des dates\n",
    "start_date = \"2022-01-01\"\n",
    "data=data_eau[(data_eau[\"date\"]>=start_date)][['libelle','date','valeur_active']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929cc98",
   "metadata": {},
   "source": [
    "### Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a36964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 334919 entries, 40076 to 470760\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   libelle        334919 non-null  object        \n",
      " 1   date           334919 non-null  datetime64[ns]\n",
      " 2   valeur_active  334919 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# retirer valeur négatives ou nulles\n",
    "data.loc[data['valeur_active']<=0, 'valeur_active'] = np.nan\n",
    "\n",
    "# retirer les valeurs extrèmes\n",
    "data.loc[data['valeur_active']>1e3, 'valeur_active']=np.nan\n",
    "\n",
    "# retirer valeur quasi-nulles et pic\n",
    "q01 = (\n",
    "    data.groupby('libelle')['valeur_active']\n",
    "      .transform(lambda x: x.quantile(0.01))\n",
    ")\n",
    "\n",
    "q99 = (\n",
    "    data.groupby('libelle')['valeur_active']\n",
    "      .transform(lambda x: x.quantile(0.99))\n",
    ")\n",
    "data.loc[(data['valeur_active'] <= q01) | (data['valeur_active'] >= q99), 'valeur_active'] = np.nan\n",
    "\n",
    "# retirer nan\n",
    "data = data[data[\"valeur_active\"].notna()].copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e888ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer les compteurs avec moins de 80% de données\n",
    "nbre_valeur_par_compteur=(data\n",
    "    .groupby('libelle')['valeur_active']\n",
    "    .count())\n",
    "seuil = 0.8 * nbre_valeur_par_compteur.max()\n",
    "libelles_volumineux = nbre_valeur_par_compteur[nbre_valeur_par_compteur > seuil].index\n",
    "data=data[data['libelle'].isin(libelles_volumineux)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fa330",
   "metadata": {},
   "source": [
    "### Clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5b99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenne_par_compteur=data.groupby('libelle')['valeur_active'].mean().reset_index()\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(moyenne_par_compteur[['valeur_active']])\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "moyenne_par_compteur[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d584ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_principal = moyenne_par_compteur['cluster'].value_counts().idxmax()\n",
    "libelles_principaux = moyenne_par_compteur[moyenne_par_compteur['cluster'] == cluster_principal]['libelle']\n",
    "data=data[data['libelle'].isin(libelles_principaux)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6447aaa",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9deb8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8715/4054849344.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_resampled = data.groupby('libelle', group_keys=False).apply(resample_and_interpolate).reset_index()\n"
     ]
    }
   ],
   "source": [
    "def resample_and_interpolate(group):\n",
    "    # Trier par date\n",
    "    group = group.sort_values('date').set_index('date')\n",
    "    \n",
    "    # Resample quotidien uniquement avec moyenne pour doublon\n",
    "    group_num = group[['valeur_active']].resample('D').mean()\n",
    "    \n",
    "    # Interpolation time\n",
    "    group_num['valeur_active'] = group_num['valeur_active'].interpolate(method='time')\n",
    "    \n",
    "    # Remettre libelle\n",
    "    group_num['libelle'] = group['libelle'].iloc[0]\n",
    "    \n",
    "    return group_num\n",
    "\n",
    "# Appliquer par libelle\n",
    "#group_keys=False pour que le libelle ne soit pas ajouté comme index supplémentaire\n",
    "#reset index pour mettre les dates resamplée en colonnes\n",
    "data_resampled = data.groupby('libelle', group_keys=False).apply(resample_and_interpolate).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7767c",
   "metadata": {},
   "source": [
    "### Bilan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bae15c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de compteurs initiaux : 502\n",
      "Nombre de compteurs finaux : 183\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre de compteurs initiaux : {len(data_eau['libelle'].unique())}\")\n",
    "print(f\"Nombre de compteurs finaux : {len(data_resampled['libelle'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b27073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199300 entries, 0 to 199299\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   date           199300 non-null  datetime64[ns]\n",
      " 1   valeur_active  199300 non-null  float64       \n",
      " 2   libelle        199300 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945d157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to Darts.DLinear standard columns name\n",
    "data_resampled=data_resampled.rename(columns={'date':'ds', 'valeur_active':'y', 'libelle':'unique_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac943ccc",
   "metadata": {},
   "source": [
    "## Création de la classe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "510c2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLinearDataset(Dataset):\n",
    "    def __init__(self, df:pd.DataFrame, moving_avg_window:int, windows_batch_size:int, inference_windows_batch_size:int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - df: pd.Dataframe with columns [unique_id, ds, y]\n",
    "        - transform: Optional transforms to apply to samples\n",
    "        - moving_avg_window : int taille de la fenetre de moyenne mobile pour le calcul de trend\n",
    "        - windows_batch_size : int taille de la fenetre de backcast\n",
    "        - inference_windows_batch_size : int taille de la fenetre de forecast\n",
    "        \"\"\"\n",
    "        # Pivot\n",
    "        df_pivot = df.pivot(index=\"ds\", columns=\"unique_id\", values=\"y\")\n",
    "        # back and forward fill (dans le temps)\n",
    "        self.data = df_pivot.sort_index().ffill().bfill().values\n",
    "\n",
    "        self.moving_avg_window=moving_avg_window\n",
    "        self.windows_batch_size=windows_batch_size\n",
    "        self.inference_windows_batch_size=inference_windows_batch_size\n",
    "        self.total_window = moving_avg_window + windows_batch_size + inference_windows_batch_size - 1\n",
    "\n",
    "        ###SECURITE###\n",
    "        # parametre window >= 1\n",
    "        assert self.moving_avg_window >=1, \"moving_avg_window must be greater or equal 1\"\n",
    "        assert self.windows_batch_size >=1, \"windows_batch_size must be greater or equal 1\"\n",
    "        assert self.inference_windows_batch_size >=1, \"inference_windows_batch_size must be greater or equal 1\"\n",
    "        assert self.moving_avg_window%2 ==1, \"moving_avg_window must odd\"\n",
    "        \n",
    "        # la série doit être de longueur au moins égale à total_window\n",
    "        assert self.data.shape[0]>=self.total_window, \"taille de série insuffisante\"\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples\n",
    "        used by the data loader\n",
    "        \"\"\"\n",
    "        # indice de 0 à self.data.shape[0]-self.total_window \n",
    "        return self.data.shape[0]-self.total_window +1\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch a single sample by index.\n",
    "        This is called by DataLoader to build batches.\n",
    "        \"\"\"\n",
    "        # indice de 0 à self.data.shape[0]-self.total_window \n",
    "        assert idx <= self.data.shape[0]-self.total_window, \"indice trog grand\"\n",
    "\n",
    "        # Extract features and labels\n",
    "        features = self.data[idx:idx+self.moving_avg_window+self.windows_batch_size-1, :].T\n",
    "        labels = self.data[idx+self.moving_avg_window+self.windows_batch_size-1:idx+self.total_window, :].T\n",
    "        # convert into tensor\n",
    "        features = torch.tensor(features)\n",
    "        labels = torch.tensor(labels)\n",
    "        # Apply transforms if provided\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afb747",
   "metadata": {},
   "source": [
    "## Création de la classe DLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3519c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DLinearWithSeriesNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    DLinear avec normalisation par série intégrée.\n",
    "    Args:\n",
    "        - moving_avg_window : int taille de la fenetre de moyenne mobile pour le calcul de trend\n",
    "        - windows_batch_size : int taille de la fenetre de backcast\n",
    "        - inference_windows_batch_size : int taille de la fenetre de forecast\n",
    "\n",
    "    Input shape : [Batch, Channels, windows_batch_size]\n",
    "    Output shape : [Batch, Channels, pred_len, inference_windows_batch_size]\n",
    "    \"\"\"\n",
    "    def __init__(self, moving_avg_window:int, windows_batch_size:int, inference_windows_batch_size:int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.moving_avg_window=moving_avg_window\n",
    "        self.windows_batch_size=windows_batch_size\n",
    "        self.inference_windows_batch_size=inference_windows_batch_size\n",
    "\n",
    "        # création des deux modeles linéaires\n",
    "        self.linear_trend = nn.Linear(self.windows_batch_size, self.inference_windows_batch_size)\n",
    "        self.linear_seasonal = nn.Linear(self.windows_batch_size, self.inference_windows_batch_size)\n",
    "\n",
    "        ###SECURITE###\n",
    "        # parametre window >= 1\n",
    "        assert self.moving_avg_window >=1, \"moving_avg_window must be greater or equal 1\"\n",
    "        assert self.windows_batch_size >=1, \"windows_batch_size must be greater or equal 1\"\n",
    "        assert self.inference_windows_batch_size >=1, \"inference_windows_batch_size must be greater or equal 1\"\n",
    "        assert self.moving_avg_window%2 ==1, \"moving_avg_window must odd\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, C, W] avec W = moving_avg_window + windows_batch_size - 1\n",
    "        \"\"\"\n",
    "        # --- Normalisation par série ---\n",
    "        # mean/std sur la dimension temporelle wbs\n",
    "        mean = x.mean(dim=2, keepdim=True)\n",
    "        std = x.std(dim=2, keepdim=True) + 1e-5  # éviter division par 0\n",
    "        xn = (x - mean) / std \n",
    "\n",
    "        # --- DLinear (décomposition + linear maps) ---\n",
    "        # moyenne mobile = convolution par canal\n",
    "        B, C, wbs = x.shape\n",
    "        kernel = torch.ones(C, 1, self.moving_avg_window, device=x.device) / self.moving_avg_window   # [C, 1, maw]\n",
    "        # F.conv1d prend des poids de shape [out_channels, in_channels, kernel_size]\n",
    "        trend = F.conv1d(x, kernel, groups=C)  # groups=C pour appliquer canal par canal\n",
    "        # trend aura pour shape : [B, C, W - maw + 1] c'est à dire [B, C, wbs]\n",
    "        # Décomposition simple en tronquant x équitablement à droite et à gauche\n",
    "        season = x[:, :, (self.moving_avg_window-1)//2 : - (self.moving_avg_window-1)//2] - trend\n",
    "\n",
    "        # Linéaires independent par canal\n",
    "        trend_out = self.linear_trend(trend)                  # [B, C, wbs]\n",
    "        season_out = self.linear_seasonal(season)             # [B, C, wbs]\n",
    "\n",
    "        y_norm = trend_out + season_out                       # [B, C, iwbs]\n",
    "        # y_norm = y_norm.permute(0, 2, 1)                      # [B, pred_len, C]\n",
    "\n",
    "        # --- Dénormalisation ---\n",
    "        y = y_norm * std + mean  # broadcast sur pred_len\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c8067ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "maw, wbs, iwbs = 7, 10, 10\n",
    "model = DLinearWithSeriesNorm(maw, wbs, iwbs)\n",
    "\n",
    "x = torch.randn(10, 3, maw+wbs-1)\n",
    "y = model(x)\n",
    "print(y.shape)  # torch.Size([16, 24, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece6667",
   "metadata": {},
   "source": [
    "## Chargement des données dans le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c863355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du dataset : 1063\n",
      "dimensions X : torch.Size([183, 24])\n",
      "dimensions y : torch.Size([183, 10])\n"
     ]
    }
   ],
   "source": [
    "# exemple d'utilisation\n",
    "DLDS=DLinearDataset(data_resampled,\n",
    "                params['moving_avg_window'],\n",
    "                params['windows_batch_size'],\n",
    "                params['inference_windows_batch_size'],\n",
    "                )\n",
    "print(f\"taille du dataset : {len(DLDS)}\")\n",
    "features, label = DLDS[0]\n",
    "print(f\"dimensions X : {features.shape}\")\n",
    "print(f\"dimensions y : {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2088a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train (80%), validation (10%), test (10%)\n",
    "\n",
    "# Définir les tailles\n",
    "train_size = int(0.8 * len(DLDS))\n",
    "val_size = int(0.1 * len(DLDS))\n",
    "test_size = len(DLDS) - train_size - val_size\n",
    "\n",
    "# Définir les indices pour chaque split (chronologique)\n",
    "train_indices = list(range(0, train_size))\n",
    "val_indices = list(range(train_size, train_size + val_size))\n",
    "test_indices = list(range(train_size + val_size, len(DLDS)))\n",
    "\n",
    "# Créer les sous-ensembles\n",
    "train_dataset = Subset(DLDS, train_indices)\n",
    "val_dataset = Subset(DLDS, val_indices)\n",
    "test_dataset = Subset(DLDS, test_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # shuffle ok pour l'entraînement\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)     # pas de shuffle\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)   # pas de shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96ac841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DLinearWithSeriesNorm(params['moving_avg_window'],\n",
    "                            params['windows_batch_size'],\n",
    "                            params['inference_windows_batch_size'],\n",
    "                            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
